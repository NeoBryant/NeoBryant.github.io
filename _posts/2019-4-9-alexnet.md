---
layout: post
title: 论文翻译 - ImageNet Classification with Deep Convolutional Neural Networks
category: Deep Learing 
description: 第一次提出AlexNet的论文，本文介绍了一些如今常用的深度学习技巧/方法
---



# 基于深度卷积神经网络的ImageNet分类


> 作者：Alex Krizhevsky、Ilya Sutskever、Geoffrey E. Hinton


## 摘要：

​	我们训练了一个大型的深卷积神经网络，将IMAGENET LSVRC-2010竞赛中的120万幅高分辨率图像分类为1000个不同的类别。在测试数据上，我们分别获得了 37.5% 和 17.0% 的 top-1 和 top-5 错误率，这比以前的最高水平要好得多。我们的神经网络有**6000万**个参数和**65万**个神经元，由**五个卷积层**组成，其中一部分卷积层随后是max-pooling层，还有**三个全连接层**，最后是1000-way的**Softmax**。为了使训练更快，我们使用了非饱和神经元和一个非常高效的GPU实现卷积运算。为了**减少全连接层中的过拟合**，我们采用了一种新的正则化方法，称为“**dropout**”，证明是非常有效的。在ILSVRC-2012竞赛中，我们还加入了该模型的一个**变形**，获得了15.3%的top-5测试错误率，而第二名的测试错误率为26.2%。




## 1 简介

​	目前的对象识别方法主要是利用机器学习方法。为了提高它们的性能，我们可以收集更大的数据集，学习更强大的模型，并使用更好的技术来防止过拟合。   目前为止，有标记的图像的数据集都相对较小 —— 按数万张图像的顺序排列。使用这种大小的数据集可以很好地解决简单的识别任务，特别是当它们通过保留标签的转换进行扩充时。例如，MNIST 数字识别任务的当前最佳错误率（<0.3%）接近人类水平。但现实环境中的物体表现出相当大的可变性，因此为了学会识别它们，有必要使用更大的训练集。事实上，小的图像数据集的缺点已被广泛认识，但直到最近才有可能用数百万张图像对标记的数据集进行分类。新的更大的数据集包括LabelMe，它由数十万个全分割的图像组成，以及ImageNet，它由超过 1500万 个标记的高分辨率图像组成，这些图像的类别超过2.2万。

​	要从数以百万计的图像中学习上千个对象，我们需要一个具有巨大学习能力的模型。然而，对象识别任务的巨大复杂性意味着即使是像 ImageNet 这样大的数据集也不能明确这个问题，因此我们的模型也应该有大量的先验知识来补偿我们没有的所有数据。卷积神经网络（CNN）构成了一类模型。它的性能可以通过改变深度和广度来控制，并且它也对图像的性质（即统计的平稳性和像素依赖的位置）做出了强有力的、最正确的假设。因此，与具有相似层数的标准前馈神经网络相比，CNN的连接和参数更少，因此更容易训练，而理论上最好的性能可能只是稍差一点。

​	尽管CNN具有吸引人的特性，而且尽管其局部架构相对高效，但它们在大规模应用于高分辨率图像方面仍然昂贵得令人望而却步。幸运的是，当前的GPU与高度优化的二维卷积实现相结合，其功能足以促进对有趣的大型CNN的培训，而最近的数据集（如ImageNet）包含足够多的标记示例，可以训练此类模型，而不会严重过拟合。

​	本文的具体贡献如下：我们在 ILSVRC-2010 和 ILSVRC-2012 竞赛中使用的ImageNet子集上训练了迄今为止最大的卷积神经网络之一并取得了迄今为止在这些数据集上报道的最佳结果。我们编写了一个高度优化的二维卷积GPU实现，以及训练卷积神经网络所固有的所有其他操作，我们将其公开。我们的网络包含许多新的和不寻常的功能，这些功能提高了它的性能并缩短了它的培训时间，这在第3节中有详细介绍。我们的网络规模使得过拟合成为一个重要问题，即使有120万个贴有标签的训练样本，因此我们使用了一些有效的技术来防止过拟合，如第4节所述。我们的最终网络包含**五个卷积层**和**三个全连接层**，并且这个深度似乎很重要：**我们发现移除任何卷积层（每个卷积层包含不超过模型参数的1%）都会导致性能下降。**

​	最后，网络的大小主要受当前GPU上可用内存量和我们愿意容忍的训练时间的限制。我们的网络需要**5到6天**的时间来训练两个GTX 580 3GB GPU。我们所有的实验都表明，只要等待更快的GPU和更大的数据集可用，我们的结果就能得到改善。

​	



## 2 数据集

​	ImageNet是一个超过1500万个有标签的高分辨率图像的数据集，属于大约22000个类别。这些图片是从网络上收集的，并由人类贴标机使用亚马逊公司的的Mechanical Turk众包工具进行标注。从2010年开始，作为 Pascal Visual Object Challenge 的一部分，每年举行一次名为 ImageNet Large-Scale Visual Recognition Challenge（ILSVRC）的比赛。ILSVRC使用 ImageNet 的一个子集，在**1000个类别中每个类别大约有1000个图像。总共大约有120万个训练图像、5万个验证图像和15万个测试图像**。

​	ILSVRC-2010 是唯一一个有测试集标签的ILSVRC版本，所以这是我们进行大多数实验的版本。由于我们在 ILSVRC-2012 竞赛中也加入了我们的模型，因此在第6节中，我们也在这个版本的数据集上报告了我们的结果，对于这个版本的数据集，测试集标签是不可用的。在 ImageNet 上，通常报告两个错误率：top-1和top-5，其中top-5错误率是测试图像的分数，正确的标签不在模型认为最可能的五个标签中。

​	ImageNet 由可变分辨率的图像组成，而我们的系统需要恒定的输入尺寸。因此，我们**将图像采样到256×256的固定分辨率**。对于矩形图像，我们首先重新调整图像的大小，**使较短的一侧长度为256**，然后从生成的图像中**裁剪出中心256×256补丁（patch）**。除了**从每个像素中减去训练集上的平均活动度**之外，我们没有以任何其他方式对图像进行预处理。因此，我们对网络进行了像素原始RGB值（居中）的训练。

​	

## 3 结构

​	我们的网络结构如 **图2** 所示。它包含八个学习层 - 五个卷积层和三个全连接层。下面，我们将描述我们的网络体系结构的一些新颖或不寻常的特性。第3.1-3.4节根据我们对其重要性的估计进行了分类，其中最重要的是第一节。	


![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-1.png)


> 图2：我们的CNN结构的一个图解，明确显示了两个GPU之间的职责划分。一个GPU运行图的顶层的层，而另一个GPU运行图的底层的层。两个GPU只在某些层进行通信。网络的输入是 150528 维，网络剩余层中的神经元数量是 253440–186624–64896–64896–43264–4096–4096–4096–1000。



### 3.1 ReLU 非线性

​	将一个神经元的输出f作为其输入x的函数建模的标准方法是 $$f(x)=tanh(x)$$ 或 $$f(x)=(1+e^{−x})^{−1}$$。对于梯度下降的训练时间，这些饱和非线性比非饱和非线性 $$f(x)=max(0, x)$$ 慢得多。在 Nair 和 Hinton 之后，我们将具有这种非线性的神经元称为 Rectified Linear Units 校正线性单位（relus）。用ReLU训练的深卷积神经网络比其等价的与 $$tanh$$ 单元快几倍。这在图1中进行了演示，图1显示了为达到特定四层卷积网络的 CIFAR-10 数据集的25%训练错误而需要的迭代次数。这个图表明，如果我们使用传统的饱和神经元模型，我们将无法在这项工作中用如此大的神经网络进行实验。

![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-9.png)

> 图1：具有ReLU（实线）的四层卷积神经网络在CIFAR-10上达到25％的训练错误率，比具有tanh神经元的等效网络（虚线）快六倍。 每个网络的学习率都是独立选择的，以便尽快进行培训。 没有采用任何形式的正规化。 这里展示的效果的大小因网络架构而异，但是具有ReLU的网络通常比具有饱和神经元的等效物快几倍。

​	我们不是第一个考虑 CNN传统神经元模型的替代方案。例如，Jarrett等人声称非线性f(x)=|tanh(x)|特别适用于它们的对比度或不失真类型，其次是 Caltech-101 数据集的局部平均池（local average pooling）。然而，在这个数据集上，主要关注的是防止过拟合，因此他们观察到的效果不同于我们在ReLUS时报告的加速适应训练集的能力。快速学习对大型数据集上训练的大型模型的性能有很大影响。

​	

### 3.2 在多个GPU上训练

​	一个 GTX 580 GPU只有3GB的内存，这限制了可以在其上训练的网络的最大规模。事实证明，120万个训练样本不足以训练那些太大而不能适应一个GPU的网络。因此，我们将网络分布在两个GPU上。如今的GPU特别适合于跨GPU并行化，因为它们能够直接读写彼此的内存，而不需要经过主机内存。我们使用的并行化方案基本上把一半的内核（或神经元）放在每个GPU上，还有一个技巧：GPU只在特定的层中通信。这意味着，例如，第3层的内核从第2层的所有内核映射中获取输入。但是，第4层中的内核只从位于同一GPU上的第3层中的内核映射获取输入。选择连接模式是交叉验证的一个问题，但这允许我们精确地调整通信量，直到它是计算量的可接受部分。

​	产生的架构与Ciresan等人使用的 “柱状的” CNN有些相似。除了我们的列不是独立的（参见图2）。该方案将我们的 top-1 和 top-5 错误率分别降低了1.7%和1.2%，相比之下，在每个卷积层中，在一个GPU上训练的内核数量只有一半。两个GPU网络的训练时间比 单GPU网络 略短。

> 在最后的卷积层中，一个GPU网络的内核数实际上与两个GPU网络的内核数相同。这是因为网络的大部分参数都在第一个全连接层中，该层以最后一个卷积层作为输入。因此，为了使两个网络具有大致相同数量的参数，我们没有将最后的卷积层（或其后的全连接层）的大小减半。因此，这种对比更偏向于单GPU网络，因为它大于两个GPU网络的“一半大小”。	



### 3.3 局部响应归一化

​	ReLUs具有可取的特性，即它们不需要输入正则化来防止饱和。如果至少有一些训练样本产生一个积极的输入到一个ReLU，学习将发生在该神经元。然而，我们仍然发现以下的局部正则化方案有助于推广。神经元的激励值 $$a_{x,y}^{i}$$ 通过应用在位置 $$(x,y)$$ 上的内核 $$i$$ 和 非线性RuLU计算得到，响应归一化激励值 $$b_{x,y}^{i}$$通过一下表达式给出：

![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-2.png)

其中求和操作在相同的空间位置上覆盖 $$n$$ 个“相邻”内核映射，$$n$$ 是该层中的内核总数。当然，内核映射的顺序是任意的，并在训练开始前确定。这种响应归一化实现了侧向抑制的一种形式，这种形式受到了在真实神经元中发现的类型的启发，在使用不同核计算的神经元输出之间产生了对大活动的竞争。**常数 $$k$$、$$n$$、​$$α$$ 和 ​$$β$$ 是超参数，其值由验证集确定**；我们使用 $$k=2$$、$$n=5$$、$$α=10^{−4}$$ 和 $$β=0.75$$。我们在某些层中应用了非线性ReLU后应用了这种归一化操作（见第3.5节）。

​	该方案与Jarrett等人的局部对比度归一化（ the local contrast normalization）方案有些相似。但是我们的方案会更准确地称为“亮度归一化（brightness normalization）”，因为我们不减去平均激励值。响应归一化将我们的 top-1 和 top-5 错误率分别降低1.4%和1.2%。我们还验证了该方案在CIFAR-10数据集上的有效性：一个四层CNN在没有归一化的情况下得到了13%的测试错误率，在归一化的情况下为11%。



### 3.4 重叠池化

​	CNN中的池化层汇总了同一核映射中相邻神经元群的输出。传统上，由相邻的池化单元汇总的相邻神经元群不会重叠。更精确地说，池化层可以被认为是由一个间隔 $$s$$ 像素的池化单元网格组成，每个单元汇总一个以池化单元位置为中心的 $$z×z$$ 大小的邻域。如果我们设置 $$s=z$$，我们将获得CNN中常用的传统局部池化。如果我们设置 $$s<z$$，我们得到重叠池化。这是我们在整个网络中使用的$$s=2$$，$$z=3$$。与非重叠方案 $$$s=2$$，$$z=2$$相比，该方案将top-1和top-5错误率分别降低了0.4%和0.3%，从而产生相同维度的输出。我们通常在训练期间观察到，**具有重叠池的模型发现更难过拟合**。



### 3.5 总体结构

​	现在我们准备描述我们的CNN总体结构。在图2中，网络包含八个带权重的层；前五个为卷积层，后三个为全连接层。最后一个全连接层的输出给到一个有1000条路径的softmax，其产生一个有1000个类别标签的分布。我们的网络最大化多元逻辑回归对象，这相当于最大化预测分布下正确标签的对数概率的训练样本的平均值。

​	第二个，第四个和第五个卷积层的内核仅连接到位于同一GPU上的前一层中的那些内核映射。（见图2）。第三卷积层的内核连接到第二层中的所有内核映射。 完全连接的层中的神经元连接到前一层中的所有神经元。 响应标准化层遵循第一和第二卷积层。 3.4节中描述的最大池化层遵循响应归一化层和第五卷积层。 ReLU非线性应用于每个卷积和完全连接层的输出。

​	第一个卷积层用 96个 大小为 $$11×11×3$$ 的内核过滤 $$224×224×3$$ 输入图像，步长为4个像素（**这是内核图中相邻神经元的感受野中心之间的距离**）。 第二个卷积层将第一个卷积层的（响应归一化和池化）输出作为输入，并用 256个 大小为 $$5×5×48$$ 的内核对其进行滤波。第三个，第四个和第五个卷积层彼此连接而没有 任何介入池化层或归一化层。 第三个卷积层具有 384个 大小为 $$3×3×256$$ 的内核，其连接到第二个卷积层的（归一化的，池化后的）输出。 第四个卷积层有 384个 大小为 $$3×3×192$$ 的内核，第五个卷积层有256个大小为$$3×3×192$$ 的内核。每个全连接层各有4096个神经元。



## 4 减少过拟合

​	我们的神经网络结构有6000万个参数。 尽管ILSVRC的1000个类别使得每个训练样本对从图像到标签的映射施加了10位约束，但是这证明模型不足以学习如此多的参数而没有严重的过拟合。 下面，我们描述了我们对抗过拟合的两种主要方式。



### 4.1 数据增广

​	减少图像数据过拟合的最简单且最常用的方法是使用标签保留的变换来人工扩充数据集。我们采用两种不同形式的数据增广，这两种形式都允许以非常少的计算从原始图像生成变换图像，因此转换后的图像不需要存储在磁盘上。在我们的实现中，转换的图像是在CPU上的Python代码中生成的，而GPU正在训练前一批图像。因此，这些数据增广方案实际上在计算上是免费的。

​	第一种形式的数据增广包括生成图像平移和水平反射。我们通过从 $$256×256$$ 图像中提取随机 $$224×224$$ 补丁（及其水平反射）并在这些提取的补丁上训练我们的网络来实现这一点。这使我们的训练集的大小增加了 2048倍，尽管由此产生的训练样本是高度相互依赖的。如果没有这种方案，我们的网络就产生严重的过拟合，这将迫使我们使用更小的网络。在测试时，网络通过提取五个 $$224×224$$ 补丁（四个角补丁和中心补丁）以及它们的水平反射（因此总共十个补丁）进行预测，并在这十个补丁上由网络中的softmax层进行的预测求平均值。

​	第二种形式的数据增广包括改变训练图像中RGB通道的强度。 具体来说，我们在整个ImageNet训练集中对RGB像素值集执行PCA（主成分分析）。 对于每个训练图像，我们添加多个找到的主成分，其幅度与相应的特征值成正比乘以从高斯绘制的随机变量，其中平均值为零，标准差为0.1。因此对于RGB图像的每个像素 $$I_{xy}=[I_{xy}^{R},I_{xy}^{G},I_{xy}^{B}]^{T}$$，我们加上如下值：


![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-3.png)


其中，$$p_i$$ 和 $$λ_i$$分别是各个RGB像素值的3×3协方差矩阵的第 $$i$$ 个特征向量和特征值，$$α_i$$是上述随机变量。 对于一张特定训练图像的所有像素，每个 $$α_i$$仅被生成一次，直到该图像再次被用于训练，此时它才被重新生成。 该方案近似地捕获自然图像的重要特征，即，对象特征对于照明的强度和颜色的变化是不变的。 该方案将 top-1个错误率降低了1％以上。



### 4.2 随机失活

​	结合许多不同模型的预测值是减少测试误差的一种非常成功的方法，但对于已经需要几天训练的大型神经网络来说，它似乎太昂贵了。然而，有一种非常有效的模型组合版本，在训练期间仅花费大约两倍。最近引入的技术称为“**dropout（随机失活）**”，包括将每个隐藏神经元的输出以0.5的概率设置为零。被“随机失活”的神经元对前馈传递没有贡献，并且不参与反向传播。因此，每次输入时，神经网络都会采样不同的架构，但所有这些架构都会共享权重。该技术减少了神经元的复杂共同适应，因为神经元不能依赖于特定其他神经元的存在。因此，它被迫学习更强大的特征，这些特征与其他神经元的许多不同随机子集一起使用是有用的。在测试时，我们使用所有神经元但是将它们的输出乘以0.5，这是采用由指数多个丢失网络产生的预测分布的几何平均值的合理近似值。

​	我们在图2的前两个全连接层中使用了随机失活。如果没有随机失活，我们的网络就会出现严重的过拟合。随机失活大约使收敛所需的迭代次数加倍。





## 5 学习的细节

​	我们使用随机梯度下降训练我们的模型，批量大小为 128个 样本，动量为 0.9，权重衰减为 0.0005。 我们发现，这种数值小的权重衰减对于模型学习很重要。 换句话说，这里的权重衰减不仅仅是一个正则化器：它减少了模型的训练误差。 权重 $$w$$ 的更新规则是


![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-4.png)


其中 $$i$$ 是迭代下标，$$v$$ 是动量变量，$$\epsilon$$ 是学习率，$$\langle\frac{\partial L}{\partial w}|_{w_{i}}\rangle_{D_i}$$是关于 $$w$$ 的目标导数的第 $$i$$ 批次 $$D_i$$的平均值，在 $$w_i$$处评估。

​	我们**用标准差为 0.01，均值为 0 的高斯分布初始化每层中的权重**。 我们**用常数1初始化了第二，第四和第五卷积层以及全连接层中的神经元偏置项**。这种初始化通过为ReLU提供正输入来加速学习的早期阶段。 我们**用常数0初始化剩余的层中的神经元偏差**。

​	我们**对所有层使用了相同的学习率**，我们在整个训练过程中手动调整。 我们遵循的启发法是**当验证错误率在当前学习率下停止改善时，则将学习率除以10。学习率初始化为0.01**，并在终止前减少三次。 我们通过120万张图像的训练集训练网络大约90个周期，这在两个NVIDIA GTX 580 3GB GPU上花费了五到六天。

​	



## 6 结果

​	我们将在ILSVRC-2010上的结果总结在表1中。我们的网络实现了 top-1 和 top-5 的测试集错误率分别为37.5％和17.0％5。 在ILSVRC-2010竞赛期间取得的最佳表现为47.1％和28.2％，采用的方法平均了六种稀疏编码模型在不同特征上训练的预测，从那时起，最佳公开的结果为45.7％和 25.7％，采用的方法是对两种类型的密集采样特征计算的Fisher Vectors（FV）训练的两个分类器的预测进行平均。


![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-5.png)


> 表1：ILSVRC-2010测试集的结果的比较。 斜体部分是其他人获得的最佳结果。



​	我们还用我们的模型参加了ILSVRC-2012竞赛，并在表2中报告了我们的结果。由于ILSVRC-2012测试集标签不公开，我们无法报告我们尝试的所有模型的测试错误率。在本段的剩余部分，我们使用验证和测试错误率可以互换，因为根据我们的经验，它们的差异不超过0.1％（见表2）。本文描述的CNN实现了top-5的错误率为18.2％。平均五个相似CNN的预测给出16.4％的错误率。训练一个CNN，在最后一个池化层上增加第六个卷积层，对整个ImageNet 2011秋季版本（1500万个图像，22000个类别）进行分类，然后在ILSVRC-2012上对其进行 “**微调（fine-tunin）**”，得出错误率为16.6％。对上述5个CNN在整个2011年秋季版预留中预训练的两个CNN的预测进行平均后，错误率为15.3％。第二个最好的测试条目实现了26.2％的错误率，采用的方法平均了从不同类型的密集采样特征计算的FV训练的多个分类器的预测。


![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-6.png)


> 表2: 在ILSVRC-2012验证集和测试集上的错误率低比较。斜体部分是其他人达到的最佳结果。带星号*的部分是"预训练”后来分类整个ImageNet 2011秋季版。详见第6节细节。

​	最后，我们还报告了2009年秋季版ImageNet的错误率，包括10184个类别和890万个图像。 在这个数据集上，我们**遵循文献中的惯例，即使用一半图像进行训练，一半进行测试**。 由于没有确定的测试集，我们的分割必然不同于之前作者使用的分割，但这并不会明显影响结果。 我们在该数据集上的 top-1 和 top-5 错误率分别为67.4％和40.9％，通过上述网络获得，但在最后一个池化层上有一个额外的第六个卷积层。 该数据集的最佳公开结果为78.1％和60.9％。



### 6.1 定性评估

​	图3显示了网络的两个数据连接层学习的卷积内核。 该网络已经学习了各种频率选择性和方向选择性内核，以及各种彩色斑点。 请注意两个GPU所展示的专业化，这是第3.5节中描述的连接受限的结果。 GPU 1上的内核主要与颜色无关，而GPU 2上的内核主要是颜色特定的。 这种特化在每次运行期间发生，并且独立于任何特定的随机权重初始化（以GPU的重新编号为模）。


![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-7.png)


> 图3：在 $$224×224×3$$ 输入图像上由第一卷积层学习的96个大小为 $$11×11×3$$ 的卷积核。 在GPU 1上学习了前48个内核，而在GPU 2上学习了最后48个内核。有关详细信息，请参阅第6.1节。

​	在图4的左侧部分中，我们通过计算八个测试图像的 top-5 个预测来定性评估网络学到了什么。 请注意，即使偏离中心的对象（例如左上角的螨虫）也可以通过网络识别。 大多数 top-5 标签看似合理。 例如，只有其他类型的猫被认为是豹子的合理标签。 在某些情况下（格栅，樱桃），对于照片的预期焦点存在真正的模糊性。


![image]({{site.baseurl}}/assets/img/dl/2019_4_9/1-8.png)


> 图4：（左）8个ILSVRC-2010测试图像和我们模型认为最可能的5个标签。 正确的标签写在每个图像下面，分配给正确标签的概率也用红色条显示（如果恰好位于前5个）。 （右）第一栏中的五个ILSVRC-2010测试图像。 其余列显示了六个训练图像，这六个训练图像在最后一个隐藏层中产生特征向量，其中距离测试图像的特征向量的欧几里得距离最小。

​	探究网络视觉知识的另一种方法是考虑最后一个4096维隐藏层的图像引起的特征激活。如果两个图像产生具有小欧几里德分离的特征激活矢量，我们可以说神经网络的较高级别认为它们是相似的。图4显示了来自测试集的五个图像和来自训练集的六个图像，根据该度量，每个图像与它们中的每一个最相似。请注意，在像素级别，检索到的训练图像通常不会在L2中与第一列中的查询图像接近。例如，被捡的狗和大象以各种姿势出现。我们在补充材料中展示了更多测试图像的结果。

​	通过使用两个4096维实数向量之间的欧几里德距离来计算相似性是低效的，但是通过训练自动编码器将这些矢量压缩为短二进制码可以使其有效。这应该产生一种比将自动编码器应用于原始像素更好的图像检索方法，它不使用图像标签，因此倾向于检索具有相似边缘图案的图像，无论它们是否在语义上类似。



## 7 讨论

​	我们的研究结果表明，大型深度卷积神经网络能够使用纯监督学习在高度具有挑战性的数据集上实现破纪录的结果。值得注意的是，如果移除任意一个卷积层，我们的网络性能会下降。例如，删除任何中间层会导致网络的 top-1性能损失约2％。所以深度对于实现我们的结果非常重要。

​	为了简化我们的实验，我们没有使用任何无监督的预训练，即使我们期望它会有所帮助，特别是如果我们获得足够的计算能力来显着增加网络的大小而不会获得相应的标记数据量的增加。到目前为止，我们的结果已经有所改善，因为我们已经使我们的网络变得更大并且训练更长，但是为了匹配人类视觉系统的颞下通路，我们还有很多个数量级的要求。最终，我们希望在视频序列上使用非常大且深度的卷积网络，其中时间结构提供了非常有用的信息，这些信息在静态图像中缺失或不那么明显。



~~end~~


**以上翻译源于机翻 & 手动修改，可能存在错误，若发现可通过邮箱向我留言**